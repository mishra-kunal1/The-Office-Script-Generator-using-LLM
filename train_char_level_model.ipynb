{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf2e5aff-23cc-4b78-b230-88a21c1133a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaled_model_config\n",
    "my_config=scaled_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68033122-7188-4495-b66b-297c7ac7087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model defined with the follwing paramters\n",
      "batch-size: 64\n",
      "block-size: 256\n",
      "max-iters: 6500\n",
      "eval-interval: 500\n",
      "lr: 0.0003\n",
      "eval-iters: 200\n",
      "embed-size: 384\n",
      "Iter     0 Train loss 4.7994 Val loss 4.7840\n",
      "Iter   500 Train loss 1.7759 Val loss 1.8511\n",
      "Saving model at iter 500 with val loss 1.8511\n",
      "Iter  1000 Train loss 1.4834 Val loss 1.5689\n",
      "Saving model at iter 1000 with val loss 1.5689\n",
      "Iter  1500 Train loss 1.3569 Val loss 1.4285\n",
      "Saving model at iter 1500 with val loss 1.4285\n",
      "Iter  2000 Train loss 1.2891 Val loss 1.3622\n",
      "Saving model at iter 2000 with val loss 1.3622\n",
      "Iter  2500 Train loss 1.2188 Val loss 1.3043\n",
      "Saving model at iter 2500 with val loss 1.3043\n",
      "Iter  3000 Train loss 1.1801 Val loss 1.2708\n",
      "Saving model at iter 3000 with val loss 1.2708\n",
      "Iter  3500 Train loss 1.1481 Val loss 1.2395\n",
      "Saving model at iter 3500 with val loss 1.2395\n",
      "Iter  4000 Train loss 1.1229 Val loss 1.2156\n",
      "Saving model at iter 4000 with val loss 1.2156\n",
      "Iter  4500 Train loss 1.1047 Val loss 1.2079\n",
      "Saving model at iter 4500 with val loss 1.2079\n",
      "Iter  5000 Train loss 1.0876 Val loss 1.1921\n",
      "Saving model at iter 5000 with val loss 1.1921\n",
      "Iter  5500 Train loss 1.0723 Val loss 1.1845\n",
      "Saving model at iter 5500 with val loss 1.1845\n",
      "Iter  6000 Train loss 1.0596 Val loss 1.1777\n",
      "Saving model at iter 6000 with val loss 1.1777\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from model import BigramLanguageModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#defining the parameters\n",
    "assert(my_config.head_size*my_config.num_heads==my_config.embed_size)\n",
    "batch_size=my_config.batch_size\n",
    "block_size=my_config.block_size\n",
    "max_iters=my_config.max_iters\n",
    "eval_interval=my_config.eval_interval\n",
    "lr=my_config.lr\n",
    "eval_iters=my_config.eval_iters\n",
    "embed_size=my_config.embed_size\n",
    "num_head=my_config.num_heads\n",
    "n_blocks=my_config.n_blocks\n",
    "dropout=my_config.dropout\n",
    "vocab_size=my_config.vocab_size\n",
    "model_config = {key: value for key, value in vars(my_config).items() if not key.startswith('__')}\n",
    "\n",
    "\n",
    "best_val_loss=1e9\n",
    "out_text_folder='saved_text/'\n",
    "out_model_folder='saved_models'\n",
    "if not os.path.exists(out_text_folder):\n",
    "    os.makedirs(out_text_folder)\n",
    "if not os.path.exists(out_model_folder):\n",
    "    os.makedirs(out_model_folder)\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "with open('output.txt', 'r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "char_to_id={ch:id for id,ch in enumerate(chars)}\n",
    "id_to_char={id:ch for id,ch in enumerate(chars)}\n",
    "encode=lambda s: [char_to_id[ch] for ch in s]\n",
    "decode=lambda l: ''.join([id_to_char[id] for id in l])\n",
    "\n",
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "n=int(len(data)*0.9)\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data=train_data if split=='train' else val_data\n",
    "    ix=torch.randint(0,len(data)-block_size,(batch_size,))\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to(device),y.to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimte_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses=torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x,y=get_batch(split)\n",
    "            logits,loss=model(x,y)\n",
    "            losses[k]=loss.item()\n",
    "        out[split+'_loss']=losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "model=BigramLanguageModel(my_config).to(device)\n",
    "print(\"model defined with the follwing paramters\")\n",
    "print('batch-size:',batch_size)\n",
    "print('block-size:',block_size)\n",
    "print('max-iters:',max_iters)\n",
    "print('eval-interval:',eval_interval)\n",
    "print('lr:',lr)\n",
    "print('eval-iters:',eval_iters)\n",
    "print('embed-size:',embed_size)\n",
    "\n",
    "optimizer=torch.optim.AdamW(model.parameters(),lr=lr)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if(iter%eval_interval==0):\n",
    "        losses=estimte_loss()\n",
    "        print(f'Iter {iter:5d} Train loss {losses[\"train_loss\"]:.4f} Val loss {losses[\"val_loss\"]:.4f}')\n",
    "        if losses['val_loss'] < best_val_loss:\n",
    "            best_val_loss = losses['val_loss']\n",
    "            if iter > 0:\n",
    "                torch.save({\n",
    "                'epoch': iter,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': losses['val_loss'],\n",
    "                'config': model_config,\n",
    "                }, f'{out_model_folder}/model.pt')\n",
    "                print(f'Saving model at iter {iter} with val loss {losses[\"val_loss\"]:.4f}')\n",
    "    x,y=get_batch('train')\n",
    "    logits,loss=model(x,y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#generate text\n",
    "# context=torch.tensor(encode('To be or not'),dtype=torch.long).unsqueeze(0).to(device)\n",
    "# #context=torch.zeros(1,8,dtype=torch.long).to(device)\n",
    "# generated_vector=decode(((model.generate(context,1000))[0]).tolist())\n",
    "\n",
    "# #put the generated text in a file\n",
    "# with open(f'{out_text_folder}/generated_text.txt', 'w',encoding='utf-8') as f:\n",
    "#     f.write(generated_vector)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dfa566-4248-41a5-bcfb-3ab7ce41cc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
